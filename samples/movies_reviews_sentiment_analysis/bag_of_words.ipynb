{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled reviews: (25000, 3)\nlabeled reviews columns: ['id' 'sentiment' 'review']\n"
     ]
    }
   ],
   "source": [
    "# The purpose is to classify a review (text) as positive or negative using labeled review already tagged\n",
    "# as positive / negative, then we build a vocabulary from our reviews and turn each review to vector\n",
    "# of all the words in the voc and the amount of occurrences in the review.\n",
    "\n",
    "# Loading the reviews\n",
    "import pandas as pd\n",
    "\n",
    "MAX_VOC_WORDS = 5000\n",
    "RANDOM_FOREST_ESTIMATORS = 100\n",
    "\n",
    "labeled_train_review = pd.read_csv(\"./data/movie_reviews/labeledTrainData.tsv\", header=0, delimiter=\"\\t\", \n",
    "                                   quoting=3)\n",
    "\n",
    "# Verify the number of reviews that were read (100,000 in total)\n",
    "print \"labeled reviews: {}\".format(labeled_train_review.shape)\n",
    "print \"labeled reviews columns: {}\".format(labeled_train_review.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def review_to_words(review, remove_stopwords=False):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review, \"html5lib\").get_text()\n",
    "    #  \n",
    "    # 2. Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "    return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorizing reviews\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Clean reviews from HTML Tags, stop words, non-alphabetical characters and upper case\n",
    "num_reviews = labeled_train_review[\"review\"].size\n",
    "clean_train_reviews = []\n",
    "\n",
    "for i in xrange(0, num_reviews):\n",
    "    clean_train_reviews.append(review_to_words(labeled_train_review[\"review\"][i]))\n",
    "\n",
    "# We can use the vectorizer pre processing but in that case i preferred the build the cleaning process myself\n",
    "vectorizer = CountVectorizer(analyzer=\"word\", tokenizer=None, preprocessor=None, stop_words=None,\n",
    "                             max_features=MAX_VOC_WORDS)\n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "train_data_features = train_data_features.toarray()\n",
    "\n",
    "print \"words vec shape: {}\".format(train_data_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators=RANDOM_FOREST_ESTIMATORS)\n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest = forest.fit(train_data_features, labeled_train_review[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'll test our model on test data\n",
    "test_reviews = pd.read_csv(\"./data/movie_reviews/testData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n",
    "\n",
    "clean_test_reviews = []\n",
    "\n",
    "for i in xrange(0, len(test_reviews['review'])):\n",
    "    clean_review = review_to_words(test_reviews[\"review\"][i])\n",
    "    clean_test_reviews.append(clean_review)\n",
    "\n",
    "# Get a bag of words for the test set, and convert to a numpy array\n",
    "test_reviews_data_features = vectorizer.transform(clean_test_reviews).toarray()\n",
    "\n",
    "# Use the random forest to make sentiment label predictions\n",
    "result = forest.predict(test_reviews_data_features)\n",
    "\n",
    "# Copy the results to a pandas dataframe with an \"id\" column and\n",
    "# a \"sentiment\" column\n",
    "output = pd.DataFrame(data={\"id\": test_reviews[\"id\"], \"sentiment\": result})\n",
    "\n",
    "# Use pandas to write the comma-separated output file\n",
    "output.to_csv(\"./data/movie_reviews/output.csv\", index=False, quoting=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
